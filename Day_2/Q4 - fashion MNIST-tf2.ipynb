{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1561972863704,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "TCKHChmFfyVL",
    "outputId": "6c860b7c-653d-4d6e-df47-18091cf262ef"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1561973241036,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "4-eGKQNGgfCm",
    "outputId": "0985a57e-8fa2-46bb-d7e9-ad6ccd411253"
   },
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_data, valid_data, train_labels, valid_labels = \\\n",
    "    train_test_split(train_data, train_labels, test_size=0.1, shuffle=True)\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_data = train_data.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "\n",
    "valid_data = valid_data / 255.\n",
    "valid_data = valid_data.reshape(-1, 784)\n",
    "valid_data = valid_data.astype(np.float32)\n",
    "valid_labels = valid_labels.astype(np.int32)\n",
    "\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(valid_data.shape, valid_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyQ9luIZk-4j"
   },
   "outputs": [],
   "source": [
    "def one_hot_label(image, label):\n",
    "  label = tf.one_hot(label, depth=10)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1561973242150,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "jl0Z9pl7k8SO",
    "outputId": "c9399fd3-378b-4003-f33e-686afda3f516"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 2\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "\n",
    "# for test\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_data, valid_labels))\n",
    "valid_dataset = valid_dataset.map(one_hot_label)\n",
    "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxm7uM4Vg8Y1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(# TODO)\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(# TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5066,
     "status": "ok",
     "timestamp": 1561969429025,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "w5wTN0SdhgUy",
    "outputId": "938a498f-0e09-435d-c983-1c613bcb4625"
   },
   "outputs": [],
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "for images, labels in train_dataset.take(1):\n",
    "  predictions = model(images[0:1], training=False)\n",
    "  print(\"Predictions: \", predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5062,
     "status": "ok",
     "timestamp": 1561969429026,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "q0yMruVchi4z",
    "outputId": "e3727a8c-8b85-4753-f2ec-f67a8551a43c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLqC2Qx6hjFc"
   },
   "outputs": [],
   "source": [
    "# use Adam optimizer \n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc_object = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# record loss and accuracy for every epoch\n",
    "mean_loss = tf.keras.metrics.Mean(\"loss\")\n",
    "mean_accuracy = tf.keras.metrics.Mean(\"accuracy\")\n",
    "\n",
    "# save loss and accuracy history for plot\n",
    "loss_history = []\n",
    "accuracy_history = [(0, 0.0)]\n",
    "\n",
    "val_loss_history = []\n",
    "val_accuracy_history = [(0, 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(global_step):\n",
    "  val_acc_object = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "  val_mean_loss = tf.keras.metrics.Mean(\"loss\")\n",
    "  val_mean_accuracy = tf.keras.metrics.Mean(\"accuracy\")\n",
    "\n",
    "  for images, labels in valid_dataset:\n",
    "    predictions = model(images, training=False)\n",
    "    val_loss_value = loss_object(labels, predictions)\n",
    "    val_acc_value = val_acc_object(labels, predictions)\n",
    "    \n",
    "    val_mean_loss(val_loss_value)\n",
    "    val_mean_accuracy(val_acc_value)\n",
    "    \n",
    "  print(\"valid loss: {:.4g}, valid accuracy: {:.4g}%\".format(val_mean_loss.result(),\n",
    "                                                             val_mean_accuracy.result() * 100))\n",
    "\n",
    "  val_loss_history.append((global_step.numpy(), val_mean_loss.result().numpy()))\n",
    "  val_accuracy_history.append((global_step.numpy(), val_mean_accuracy.result().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1561969894606,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "5AwE2tM6kpZe",
    "outputId": "2956cd71-5308-40e0-c901-5da1bc4d3c98"
   },
   "outputs": [],
   "source": [
    "print(\"start training!\")\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "validation(global_step)\n",
    "num_batches_per_epoch = int(len(train_data) / batch_size)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "  for step, (images, labels) in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "      predictions = model(images, training=True)\n",
    "      loss_value = loss_object(labels, predictions)\n",
    "      acc_value = acc_object(labels, predictions)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    global_step.assign_add(1)\n",
    "    \n",
    "    mean_loss(loss_value)\n",
    "    mean_accuracy(acc_value)\n",
    "    loss_history.append((global_step.numpy(), mean_loss.result().numpy()))\n",
    "    \n",
    "    if global_step.numpy() % 10 == 0:\n",
    "      clear_output(wait=True)\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration) \n",
    "      print(\"epochs: {:.2f}, step: {}, loss: {:.3g}, accuracy: {:.4g}% ({:.2f} examples/sec; {:.4f} sec/batch)\".format(\n",
    "          epochs, global_step.numpy(), loss_value.numpy(), acc_value.numpy()*100, examples_per_sec, duration))\n",
    "      \n",
    "  # save mean accuracy for plot\n",
    "  accuracy_history.append((global_step.numpy(), mean_accuracy.result().numpy()))\n",
    "  validation(global_step)\n",
    "  # clear the history\n",
    "  mean_accuracy.reset_states()\n",
    "\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1640,
     "status": "ok",
     "timestamp": 1561970092836,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "P5ZcVB42hqDE",
    "outputId": "eeb0edd0-c6ff-4da3-83d6-973fdcfaad8e"
   },
   "outputs": [],
   "source": [
    "plt.plot(*zip(*loss_history), label='loss')\n",
    "plt.plot(*zip(*val_loss_history), label='val_loss')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Loss value [cross entropy]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1561970092837,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "MIfLiTlehtAC",
    "outputId": "1497afe9-79be-41ab-c860-5d2918f10158"
   },
   "outputs": [],
   "source": [
    "plt.plot(*zip(*accuracy_history), label='accuracy')\n",
    "plt.plot(*zip(*val_accuracy_history), label='val_accuracy')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Accuracy value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_object.reset_states()\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "  predictions = model(images, training=False)\n",
    "  acc_object(labels, predictions)\n",
    "  \n",
    "print(\"test accuracy: {:.4g}%\".format(acc_object.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Nw5cVdvrBaf"
   },
   "outputs": [],
   "source": [
    "np.random.seed(219)\n",
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(28, 28))\n",
    "  p.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xXAtg-orCa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Q3 - fashion MNIST sol-tf.ipynb의 사본",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
