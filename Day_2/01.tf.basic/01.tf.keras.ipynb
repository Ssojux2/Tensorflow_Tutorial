{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usages of `tf.keras`\n",
    "\n",
    "* 이 코드는 [TensorFlow official Guide `tf.keras` 문서](https://www.tensorflow.org/guide/keras)를 정리한 것이다.\n",
    "* TensorFlow 2.0 부터는 중복되는 API를 정리하여 모델을 만들때 쓰는 `layer`, `loss`등을 [`tf.keras` API](https://www.tensorflow.org/api_docs/python/tf/keras)를 사용하여 만들게 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model\n",
    "\n",
    "### Sequential model\n",
    "* Two types of the sequential model\n",
    "\n",
    "#### Type I\n",
    "* `add` method를 이용하여 `layer`를 하나씩 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model1.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model1.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model1.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type II\n",
    "* 모든 `layer`들을 `list`에 담아 `Sequential`에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "  # Adds a densely-connected layer with 64 units to the model:\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  # Add another:\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  # Add a softmax layer with 10 output units:\n",
    "  layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training\n",
    "\n",
    "[`tf.keras.Model.compile`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile) takes three important arguments:\n",
    "\n",
    "* `optimizer`: This object specifies the training procedure. Pass it optimizer instances from the [`tf.train`](https://www.tensorflow.org/api_docs/python/tf/train) module, such as [`tf.train.AdamOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer), [`tf.train.RMSPropOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer), or [`tf.train.GradientDescentOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer).\n",
    "* `loss`: The function to minimize during optimization. Common choices include mean square error (`mse`), `categorical_crossentropy`, and `binary_crossentropy`. Loss functions are specified by name or by passing a callable object from the [`tf.keras.losses module`](https://www.tensorflow.org/api_docs/python/tf/keras/losses).\n",
    "* `metrics`: Used to monitor training. These are string names or callables from the [`tf.keras.metrics module`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two types in `tf.keras.Model.compile`\n",
    "\n",
    "type I\n",
    "```python\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])```\n",
    "              \n",
    "type II\n",
    "```python\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "### Input using numpy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0724 22:42:15.820505 140174394066752 deprecation.py:323] From /home/ssojux2/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 279us/sample - loss: 11.6139 - acc: 0.1010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5843 - acc: 0.1200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 11.5768 - acc: 0.1170\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 11.5726 - acc: 0.1260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.5663 - acc: 0.1200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 11.5628 - acc: 0.1330\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 11.5587 - acc: 0.1450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11.5558 - acc: 0.1530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5511 - acc: 0.1450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5453 - acc: 0.1590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c6f085048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 11.5427 - acc: 0.1540 - val_loss: 11.4288 - val_acc: 0.0600\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 11.5370 - acc: 0.1730 - val_loss: 11.4332 - val_acc: 0.0600\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 11.5349 - acc: 0.1610 - val_loss: 11.4335 - val_acc: 0.0600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 11.5286 - acc: 0.1690 - val_loss: 11.4375 - val_acc: 0.0500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 11.5254 - acc: 0.1670 - val_loss: 11.4378 - val_acc: 0.0400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 11.5212 - acc: 0.1680 - val_loss: 11.4417 - val_acc: 0.0400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 11.5158 - acc: 0.1920 - val_loss: 11.4412 - val_acc: 0.0600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 11.5117 - acc: 0.1910 - val_loss: 11.4449 - val_acc: 0.0600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 11.5098 - acc: 0.1980 - val_loss: 11.4548 - val_acc: 0.0600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 11.5021 - acc: 0.2020 - val_loss: 11.4537 - val_acc: 0.0700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7cd8130320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input using `tf.data` dataset\n",
    "\n",
    "Use the [Datasets API](https://www.tensorflow.org/guide/datasets) to scale to large datasets or multi-device training. Pass a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) instance to the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0724 22:42:17.548507 140174394066752 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.4993 - acc: 0.2046\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 11.5196 - acc: 0.2004\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4979 - acc: 0.2004\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4844 - acc: 0.1994\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4815 - acc: 0.2014\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4586 - acc: 0.2076\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4671 - acc: 0.2159\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4480 - acc: 0.2190\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4668 - acc: 0.2128\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4649 - acc: 0.2252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c386eecf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0724 22:42:18.383331 140174394066752 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4818 - acc: 0.2313 - val_loss: 11.4807 - val_acc: 0.0833\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4550 - acc: 0.2350 - val_loss: 11.4836 - val_acc: 0.0729\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4268 - acc: 0.2372 - val_loss: 11.4883 - val_acc: 0.0833\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4176 - acc: 0.2479 - val_loss: 11.4888 - val_acc: 0.0833\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4494 - acc: 0.2468 - val_loss: 11.4942 - val_acc: 0.0729\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4345 - acc: 0.2521 - val_loss: 11.4999 - val_acc: 0.0625\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4097 - acc: 0.2553 - val_loss: 11.5062 - val_acc: 0.0521\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4093 - acc: 0.2564 - val_loss: 11.5124 - val_acc: 0.0625\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3970 - acc: 0.2714 - val_loss: 11.5178 - val_acc: 0.0625\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.3939 - acc: 0.2703 - val_loss: 11.5184 - val_acc: 0.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c387699b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.6653 - acc: 0.0910\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4321 - acc: 0.2667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.432084147135416, 0.26666668]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build advanced model\n",
    "\n",
    "### Functional API\n",
    "\n",
    "* `tf.keras.Sequential` cannot represent arbitrary models.\n",
    "  * Multi-input models\n",
    "  * Multi-output models\n",
    "  * Models with shared layers (the same layer called several times)\n",
    "  * Models with non-sequential data flows (e.g. residual connections)\n",
    "  \n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) instance.\n",
    "3. This model is trained just like the `Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 143us/sample - loss: 11.7630 - acc: 0.1020\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.6275 - acc: 0.0980\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.5983 - acc: 0.0860\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.5874 - acc: 0.0970\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 11.5779 - acc: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c3863e550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model subclassing\n",
    "\n",
    "* Subclassing `tf.keras.Model`\n",
    "* define `__init__`\n",
    "  * Create layers and set them as attributes of the class instance\n",
    "* define `call`\n",
    "  * Define the forward pass\n",
    "  \n",
    "Simple class form\n",
    "```python\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    # Define your layers here.\n",
    "    pass\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    pass```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    self.num_classes = num_classes\n",
    "    # Define your layers here.\n",
    "    self.dense_1 = layers.Dense(32, activation='relu')\n",
    "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    x = self.dense_1(inputs)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    # You need to override this function if you want to use the subclassed model\n",
    "    # as part of a functional-style model.\n",
    "    # Otherwise, this method is optional.\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.num_classes\n",
    "    return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 11.6785 - acc: 0.1030\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.6433 - acc: 0.1010\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 11.6069 - acc: 0.1040\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 11.5943 - acc: 0.1020\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.5881 - acc: 0.1140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c383f7b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers\n",
    "\n",
    "Create a custom layer by subclassing [`tf.keras.layers.Layer`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) and implementing the following methods:\n",
    "\n",
    "* `build`: Create the weights of the layer. Add weights with the `add_weight` method.\n",
    "* `call`: Define the forward pass.\n",
    "* `compute_output_shape`: Specify how to compute the output shape of the layer given the input shape.\n",
    "* Optionally, a layer can be serialized by implementing the `get_config` method and the `from_config` class method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    # Be sure to call this at the end\n",
    "    super(MyLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.output_dim\n",
    "    return tf.TensorShape(shape)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "    return base_config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 11.5925 - acc: 0.1170\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5817 - acc: 0.1200\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.5781 - acc: 0.1000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.5766 - acc: 0.1070\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5747 - acc: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c44502828>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "A callback is an object passed to a model to customize and extend its behavior during training. You can write your own custom callback, or use the built-in [`tf.keras.callbacks`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) that include:\n",
    "\n",
    "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at regular intervals.\n",
    "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning rate.\n",
    "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation performance has stopped improving.\n",
    "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 11.5728 - acc: 0.1060 - val_loss: 11.4125 - val_acc: 0.1400\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.5707 - acc: 0.1340 - val_loss: 11.4092 - val_acc: 0.1600\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.5682 - acc: 0.1280 - val_loss: 11.4138 - val_acc: 0.1300\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.5676 - acc: 0.1270 - val_loss: 11.4077 - val_acc: 0.1700\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5658 - acc: 0.1380 - val_loss: 11.4029 - val_acc: 0.2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c30227a58>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore\n",
    "\n",
    "### Weights only\n",
    "\n",
    "* Save and load the weights of a model using [`tf.keras.Model.save_weights`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#save_weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 136us/sample - loss: 11.8584 - acc: 0.1010\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.6462 - acc: 0.1040\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.6243 - acc: 0.1010\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.6095 - acc: 0.1070\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5989 - acc: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c3868c710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7bf0450e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_4\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_13\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 32]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'build_input_shape': [None, 32],\n",
      "            'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_13',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_14',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_4'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 11.6315 - acc: 0.0890\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 11.6190 - acc: 0.0930\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5976 - acc: 0.0880\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5822 - acc: 0.1020\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.5759 - acc: 0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0724 22:43:22.733928 140174394066752 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "W0724 22:43:22.757243 140174394066752 hdf5_format.py:221] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Create a trivial model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
