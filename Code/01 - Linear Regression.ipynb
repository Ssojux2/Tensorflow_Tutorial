{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"01 - Linear Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z8juHB30ID_y"},"source":["# Linear Regression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8YN6sNhzIMM1"},"source":["* 주어진 데이터를 기반으로 예측값을 찾아보자\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fgFXOeQ3IGBv","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6UTdIW-gJWwr"},"source":["## Hypothesis\n","\n","* 우리가 세운 가설을 코드로 만들어봅시다.\n","\n","$$ H(x) = Wx + b $$\n","\n","* 예측해야되는 데이터는 주어집니다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R6EeL-OAJpKd","colab":{}},"source":["# 주어진 데이터를 확인해 봅시다.\n","x_data = [1, 2, 3, 4, 5]\n","y_data = [1, 2, 3, 4, 5]\n","\n","#이 데이터를 표현하는 모델을 정의해봅시다.\n","\n","W = tf.Variable(1.7) # 임의의 값\n","b = tf.Variable(0.5) # 임의의 값\n","\n","# Hpyothesis 가설\n","hypothesis = W * x_data + b\n","\n","# 표로 출력\n","plt.plot(x_data, hypothesis.numpy())\n","plt.plot(x_data, y_data, 'o')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"olIAgNvrJ1WO"},"source":["## Cost\n","$$ cost(W)=\\frac { 1 }{ m } \\sum _{i=1}^{m}{ { ({ H(x_{ i }) }-y_{ i } })^{ 2 } }  $$"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"31iigy8iLqcO","colab":{}},"source":["# Cost function == Loss Function\n","cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","\n","sq = tf.square(3) # 제곱을 해주는 함수\n","tf.print(sq)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MhRaJ2h965WJ"},"source":["# Cost Function을 조금 더 쉽게 표현해봅시다.\n","## Simplifed hypothesis\n","\n","$$ H(x) = Wx $$ \n","\n","$$ cost(W)=\\frac { 1 }{ m } \\sum _{i=1}^{m}{ { ({ H(x_{ i }) }-y_{ i } })^{ 2 } }  $$\n","\n","* b 를 W 행렬에 포함 시킬 수 있기 때문에 생략이 가능하다\n","* Cost 함수를 정의해보자\n","\n","* 차원을 축소시켜서 생각해 볼 수 있다.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ew3Jx4nX7FKZ","colab":{}},"source":["def cost_func(W, X, Y):\n","  hypothesis = X * W\n","  return tf.reduce_mean(tf.square(hypothesis - Y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bddR0hao7NJN"},"source":["## 우리가 가정한 Cost Funtion을 살펴보자\n","\n","$$ cost(W)=\\frac { 1 }{ m } \\sum _{i=1}^{m}{ { ({ H(x_{ i }) }-y_{ i } })^{ 2 } }  $$\n","\n","W = -1, cost(W) = 18.67\n","$$ cost(W)=\\frac { 1 }{ 3 } ( (-1 * 1 - 1)^2 + (-1 * 2 - 2)^2 + (-1 * 3 - 3)^2) $$\n","\n","W = 0, cost(W) = 4.67\n","$$ cost(W)=\\frac { 1 }{ 3 } ( (0 * 1 - 1)^2 + (0 * 2 - 2)^2 + (0 * 3 - 3)^2) $$\n","\n","W = 1, cost(W) = 0\n","$$ cost(W)=\\frac { 1 }{ 3 } ( (1 * 1 - 1)^2 + (1 * 2 - 2)^2 + (1 * 3 - 3)^2) $$\n","\n","W = 2, cost(W) = 4.67\n","$$ cost(W)=\\frac { 1 }{ 3 } ( (2 * 1 - 1)^2 + (2 * 2 - 2)^2 + (2 * 3 - 3)^2) $$\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DcbA7CkYH5IW","colab":{}},"source":["X = np.array([1, 2, 3])\n","Y = np.array([1, 2, 3])\n","\n","W_values = np.linspace(-3, 5, num=15) # -3 ~ 5 사이의 15개 숫자들 - 15등분\n","cost_values = []\n","\n","for feed_W in W_values:\n","    curr_cost = cost_func(feed_W, X, Y)\n","    cost_values.append(curr_cost)\n","    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))\n","    \n","# Cost Function을 시각화 해보자    \n","    \n","plt.plot(W_values, cost_values, \"b\")\n","plt.ylabel('Cost(W)')\n","plt.xlabel('W')\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3J0IwKqtJJGS"},"source":["# Cost Function을 이용해서 최적 값은 어떻게 찾는것일까?\n","\n","## Minimizing Cost == Gradient descent\n","\n","$$ cost(W)=\\frac { 1 }{ 2m } \\sum _{i=1}^{m}{ { ({ H(x_{ i }) }-y_{ i } })^{ 2 } }  $$\n","\n","$$ W:=W-\\alpha \\frac { 1 }{ m } \\sum _{i=1}^{m}{ { ({ H(x_{ i }) }-y_{ i } })^{ 2 } }  $$\n","\n","$$ \\alpha = Learning Rate $$"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4HaRA3N1JMvA","colab":{}},"source":["W = tf.Variable([4.1]) # 임의의 값\n","\n","for step in range(300):\n","    hypothesis = W * X\n","    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n","\n","    # Gradient Descent의 동작 원리\n","    lr = 0.01\n","    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n","    descent = W - tf.multiply(lr, gradient)\n","    W.assign(descent)\n","    \n","    if step % 10 == 0:\n","        print(\"step : {:3}, cost :  {:5.4f}, W : {:5.6f}\".format(step, cost.numpy(), W.numpy()[0]))\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YXaVsxPGDTdP"},"source":["# 다시 돌아와서 가설과 Cost Function을 이용해 계산해봅시다.\n","## GradientTape()\n","* 위에서는 직접 가중치의 업데이트를 진행\n","* TF에서 지원하는 함수로 업데이트할 가중치를 계산해 주는 역할\n","* Cost 함수와 예측 값으로 가중치를 얼마나 업데이트할지 결정해준다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q0Ka_VnULyZ2","colab":{}},"source":["W = tf.Variable(1.7) # 임의의 값\n","b = tf.Variable(0.5) # 임의의 값\n","\n","with tf.GradientTape() as tape:\n","  hypothesis = W * x_data + b\n","  cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","  \n","W_grad, b_grad = tape.gradient(cost, [W, b])\n","\n","print(W_grad, b_grad)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WoIf_xhLN77Q"},"source":["## assign_sub()\n","\n","* A = A - B\n","* A -= B\n","* 위의 계산을 해주는 함수\n","\n","* 가중치 값을 업데이트"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-ZeGq578MItm","colab":{}},"source":["learning_rate = 0.01\n","\n","W.assign_sub(learning_rate * W_grad)\n","b.assign_sub(learning_rate * b_grad)\n","\n","W.numpy(), b.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pwJH_SysN4LP"},"source":["### 여러번 돌려봅시다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fxj6pWjFOrkP","colab":{}},"source":["for i in range(100):\n","    with tf.GradientTape() as tape:\n","        #가설 설정\n","        hypothesis = W * x_data + b\n","        # Cost 함수 설정\n","        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","        \n","    W_grad, b_grad = tape.gradient(cost, [W, b]) # gradient 계산\n","    \n","    learning_rate = 0.01\n","    # 가중치 업데이트\n","    W.assign_sub(learning_rate * W_grad)\n","    b.assign_sub(learning_rate * b_grad)\n","    \n","    if i % 10 == 0:\n","      print(\"{:5}|{:10.4f}|{:10.4f}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))\n","\n","plt.plot(x_data, y_data, 'o')\n","plt.plot(x_data, hypothesis.numpy(), 'r-')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHcnEf1wbOej","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}