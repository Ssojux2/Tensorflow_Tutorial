{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04 - Softmax classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"9JutkdoS4X-A","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r8vMWSpBX3iX"},"source":["# Softmax classification\n","\n","* 임의의 Dataset 준비\n","* 3개의 클래스로 분류할 데이터 준비\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lZH1QvjlFBsE","colab":{}},"source":["x_data = [[1., 2., 1., 1.],\n","          [2., 1., 3., 2.],\n","          [3., 1., 3., 4.],\n","          [4., 1., 5., 5.],\n","          [1., 7., 5., 5.],\n","          [1., 2., 5., 6.],\n","          [1., 6., 6., 6.],\n","          [1., 7., 7., 7.]] # 8x4\n","y_data = [[0., 0., 1.],\n","          [0., 0., 1.],\n","          [0., 0., 1.],\n","          [0., 1., 0.],\n","          [0., 1., 0.],\n","          [0., 1., 0.],\n","          [1., 0., 0.],\n","          [1., 0., 0.]] # 8x3\n","\n","x_test = [[1., 1., 1., 1.]]\n","y_test = [[0., 0., 1.]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCPXA2luyvlN","colab_type":"text"},"source":["## 임의의 Data를 이용해서 3개의 클래스를 가지는 데이터셋 생성"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HpNjJzwwX7uz","colab":{}},"source":["#dataset을 선언합니다.\n","dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n","dataset = dataset.repeat(1).batch(8)\n","\n","nb_classes = 3 # class의 개수입니다.\n","\n","print(tf.Variable(x_data))\n","print(tf.Variable(y_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wmHTiEKcX_zD","colab":{}},"source":["#Weight and bias setting\n","W = tf.Variable(tf.random.normal([4, nb_classes]), name='weight')\n","b = tf.Variable(tf.random.normal([nb_classes]), name='bias')\n","variables = [W, b]\n","\n","tf.print(W,b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4op7dp4RyvlT","colab_type":"text"},"source":["# 가설 설정\n","\n","* 가설에서 예측한 값들을 이용해 예측값들을 확률로 표현한다.\n","\n","## $$ y_k = \\frac{exp(x_k)}{\\sum_{i=1}^{n}exp(x_i)}  $$"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kje8MUl-DOMO","colab":{}},"source":["# tf.nn.softmax computes softmax activations\n","# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n","def hypothesis_softmax(X):\n","    return tf.nn.softmax(tf.matmul(X, W) + b)\n","\n","tf.print(hypothesis_softmax(tf.Variable(x_data)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aYnGTBv2S-DS"},"source":["## 가설을 검증할 Cost 함수를 정의합니다\n","$$\n","\\begin{align}\n","cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n","cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n","\\end{align}\n","$$\n","\n","### 두 식을 한번에 쓰게되면,\n","\n","$$\n","\\begin{align}\n","cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n","\\end{align}\n","$$"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fxXa5whUIwSN","colab":{}},"source":["def loss_fn(hypothesis, labels):\n","    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1 - labels) * tf.math.log(1 - hypothesis))\n","    return cost\n","\n","optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-3BTbBLyvla","colab_type":"text"},"source":["### 학습 진행"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hOHOKhWyIzk9","scrolled":true,"colab":{}},"source":["epochs = 5000\n","\n","for step in range(epochs):\n","  for features, labels in dataset:\n","    with tf.GradientTape() as tape:\n","      loss_value = loss_fn(hypothesis_softmax(features),labels)\n","      grads = tape.gradient(loss_value, [W,b])\n","      optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n","      if step % 100 == 0:\n","            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(hypothesis_softmax(features),labels)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6iMuYpxyvld","colab_type":"text"},"source":["## Sample 데이터를 넣고 테스트해봅시다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pyNxH16II0st","colab":{}},"source":["sample_data = [[2,1,3,2]] # answer_label [[0,0,1]]\n","sample_data = np.asarray(sample_data, dtype=np.float32)\n","\n","a = hypothesis_softmax(sample_data)\n","\n","print(a)\n","print(tf.argmax(a, 1)) #index: 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rB-aJf0yvlg","colab_type":"text"},"source":["## 데이터를 이용해서 예측"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9qJfHxEnI25d","colab":{}},"source":["b = hypothesis_softmax(x_test)\n","print(b)\n","print(tf.argmax(b, 1))\n","print(tf.argmax(y_test, 1)) # matches with y_data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CkhpaF-rCMnZ","colab":{}},"source":["def accuracy_fn(hypothesis, labels):\n","    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n","    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n","    return accuracy\n","  \n","test_acc = accuracy_fn(hypothesis_softmax(x_test),y_test)\n","print(\"Testset Accuracy: {:.4f}\".format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CHq7WwDzE1oh","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}