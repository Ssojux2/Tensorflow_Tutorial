{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1722,
     "status": "ok",
     "timestamp": 1561974130082,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "HA9F-ehts7th",
    "outputId": "d8f541aa-47ab-4807-8af7-087ca8c48d6c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZOO classification\n",
    "\n",
    "### Data list\n",
    "\n",
    "1. 동물 이름  animal name:     (deleted)\n",
    "2. 털  hair     Boolean\n",
    "3. 깃털  feathers     Boolean\n",
    "4. 알  eggs     Boolean\n",
    "5. 우유 milk     Boolean\n",
    "6. 날 수있는지  airborne     Boolean\n",
    "7. 수중 생물  aquatic      Boolean\n",
    "8. 포식자  predator     Boolean\n",
    "9. 이빨이 있는지 toothed      Boolean\n",
    "10. 척추 동물  backbone     Boolean\n",
    "11. 호흡 방법  breathes     Boolean\n",
    "12. 독  venomous     Boolean\n",
    "13. 물갈퀴  fins     Boolean\n",
    "14. 다리  legs     Numeric (set of values: {0\",2,4,5,6,8})\n",
    "15. 꼬리  tail     Boolean\n",
    "16. 사육 가능한 지 domestic     Boolean\n",
    "17. 고양이 크기인지 catsize      Boolean\n",
    "18. 동물 타입 type     Numeric (integer values in range [0\",6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2464,
     "status": "ok",
     "timestamp": 1561974130848,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "-i11AGBVtU1s",
    "outputId": "8f46e150-3273-4a30-d882-d3452b150700"
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data-04-zoo.csv', delimiter=',', dtype=np.int32)\n",
    "x_train = xy[0:-10, 0:-1]\n",
    "y_train = xy[0:-10, [-1]]\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "\n",
    "x_test = xy[-10:, 0:-1]\n",
    "y_test = xy[-10:, [-1]]\n",
    "\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "nb_classes = 7  # 0 ~ 6\n",
    "\n",
    "y_train = tf.one_hot(list(y_train), nb_classes)\n",
    "y_train = tf.reshape(y_train, [-1, nb_classes])\n",
    "\n",
    "\n",
    "y_test = tf.one_hot(list(y_test), nb_classes)\n",
    "y_test = tf.reshape(y_test, [-1, nb_classes])\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(x_train.dtype, y_train.dtype)\n",
    "print(x_test.dtype, y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2454,
     "status": "ok",
     "timestamp": 1561974130852,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "vA5v-Z1butQj",
    "outputId": "941ba72a-2a44-4fe2-a9d0-20e36775c166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7) (7,)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "print(W.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가설 설정\n",
    "\n",
    "* 주어진 동물의 데이터들로 분류하는 가설 모델을 생성한다\n",
    "\n",
    "## $$ y_k = \\frac{exp(x_k)}{\\sum_{i=1}^{n}(x_i)}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2698,
     "status": "ok",
     "timestamp": 1561974131105,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "koTAYczVts_I",
    "outputId": "e5352e1d-81ed-49a9-f3f0-78638c3cb316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.59999069e-04 2.27401179e-04 2.78171992e-05 5.33371240e-05\n",
      "  3.60713638e-02 4.75822002e-01 4.87538040e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [4.62341189e-01 1.02376211e-02 5.77087572e-04 2.10983492e-03\n",
      "  3.95924877e-03 5.10393858e-01 1.03811836e-02]\n",
      " [2.59999069e-04 2.27401179e-04 2.78171992e-05 5.33371240e-05\n",
      "  3.60713638e-02 4.75822002e-01 4.87538040e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [3.16285768e-05 3.63749459e-05 5.49743891e-06 1.38476782e-04\n",
      "  3.64101082e-02 2.41978437e-01 7.21399486e-01]\n",
      " [6.03710115e-01 7.02165067e-03 5.08231635e-04 1.70391593e-02\n",
      "  4.96154325e-03 3.55353147e-01 1.14061572e-02]\n",
      " [4.62341189e-01 1.02376211e-02 5.77087572e-04 2.10983492e-03\n",
      "  3.95924877e-03 5.10393858e-01 1.03811836e-02]\n",
      " [5.01257135e-04 3.72662966e-04 2.43200357e-05 3.31651216e-04\n",
      "  4.41734828e-02 8.60141739e-02 8.68582487e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [1.02606241e-03 4.03891597e-03 1.43388158e-03 8.43230188e-02\n",
      "  1.30233884e-01 3.24181467e-01 4.54762846e-01]\n",
      " [4.62341189e-01 1.02376211e-02 5.77087572e-04 2.10983492e-03\n",
      "  3.95924877e-03 5.10393858e-01 1.03811836e-02]\n",
      " [5.28824866e-01 1.99160367e-01 6.47247536e-03 9.98598635e-02\n",
      "  8.99622589e-02 3.93485501e-02 3.63715664e-02]\n",
      " [1.95558358e-04 6.05191663e-03 3.12109682e-06 1.25014374e-03\n",
      "  8.13737452e-01 2.97497958e-02 1.49012014e-01]\n",
      " [1.07009964e-06 3.68458946e-04 2.79672179e-08 7.05822385e-05\n",
      "  7.72715151e-01 8.94580409e-03 2.17898935e-01]\n",
      " [7.84077274e-04 5.87591529e-03 1.62459223e-03 1.04183117e-02\n",
      "  1.03698082e-01 4.64605570e-01 4.12993461e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [1.36327103e-01 1.86534168e-03 2.53077538e-04 1.19299523e-03\n",
      "  1.76384498e-03 8.55810285e-01 2.78727314e-03]\n",
      " [4.90704887e-02 6.87944994e-04 1.64801299e-04 5.32987528e-04\n",
      "  4.11467074e-04 9.33443546e-01 1.56887211e-02]\n",
      " [1.02606241e-03 4.03891597e-03 1.43388158e-03 8.43230188e-02\n",
      "  1.30233884e-01 3.24181467e-01 4.54762846e-01]\n",
      " [1.01831323e-03 4.54406813e-03 1.62709388e-03 4.93650138e-03\n",
      "  8.88473317e-02 7.35671341e-01 1.63355380e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [1.38676434e-04 5.76072896e-04 6.77705742e-04 4.05399315e-03\n",
      "  2.25065537e-02 8.41476262e-01 1.30570784e-01]\n",
      " [5.66733149e-07 1.77486494e-04 3.64236961e-08 3.75827622e-05\n",
      "  2.48394370e-01 1.66112166e-02 7.34778821e-01]\n",
      " [1.38525537e-03 1.39889284e-03 1.80680636e-05 8.01300339e-05\n",
      "  2.25303665e-01 7.10618734e-01 6.11952357e-02]\n",
      " [3.51288298e-04 9.28566093e-04 1.38861160e-05 5.92121505e-05\n",
      "  6.75673544e-01 2.55810469e-01 6.71630502e-02]\n",
      " [1.38438772e-03 1.08641270e-03 8.03608156e-04 3.58135178e-04\n",
      "  6.71790773e-03 5.00053823e-01 4.89595771e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [6.66926950e-02 3.06977332e-03 1.85318606e-03 7.14841764e-03\n",
      "  6.30018190e-02 6.57644093e-01 2.00590059e-01]\n",
      " [3.57343794e-07 3.07419657e-04 7.94468065e-08 1.49351326e-04\n",
      "  2.04536140e-01 4.57549617e-02 7.49251723e-01]\n",
      " [3.16285768e-05 3.63749459e-05 5.49743891e-06 1.38476782e-04\n",
      "  3.64101082e-02 2.41978437e-01 7.21399486e-01]\n",
      " [1.32287089e-02 9.32842377e-04 1.37064815e-03 3.01757769e-04\n",
      "  8.58988333e-03 7.93348670e-01 1.82227463e-01]\n",
      " [1.66243408e-03 8.26969091e-03 1.67499960e-03 7.02442555e-03\n",
      "  1.78583279e-01 6.66938066e-01 1.35847121e-01]\n",
      " [3.26151758e-01 6.47850288e-03 6.45594788e-04 1.70756457e-03\n",
      "  2.26848782e-03 6.48371696e-01 1.43763935e-02]\n",
      " [3.68172914e-05 6.85227787e-05 4.30269665e-06 8.40579305e-05\n",
      "  2.80521531e-02 4.95332219e-02 9.22220886e-01]\n",
      " [1.57152626e-05 4.99515299e-05 4.31834360e-06 6.65557445e-06\n",
      "  1.01336120e-02 7.14066178e-02 9.18383121e-01]\n",
      " [7.84077274e-04 5.87591529e-03 1.62459223e-03 1.04183117e-02\n",
      "  1.03698082e-01 4.64605570e-01 4.12993461e-01]\n",
      " [4.62341189e-01 1.02376211e-02 5.77087572e-04 2.10983492e-03\n",
      "  3.95924877e-03 5.10393858e-01 1.03811836e-02]\n",
      " [2.29783765e-07 1.85158497e-04 7.36080139e-08 1.99200396e-04\n",
      "  7.89346159e-01 2.28499505e-03 2.07984239e-01]\n",
      " [1.31926311e-06 6.93594688e-04 3.27875796e-07 7.28046143e-05\n",
      "  3.24319869e-01 3.12120393e-02 6.43700004e-01]\n",
      " [1.75730756e-03 4.79408726e-03 1.05256448e-03 3.70487152e-03\n",
      "  1.77966699e-01 2.38365725e-01 5.72358668e-01]\n",
      " [5.41943564e-07 5.19734400e-04 7.59772760e-08 1.97426838e-04\n",
      "  3.81919473e-01 3.85341048e-02 5.78828692e-01]\n",
      " [4.47477418e-04 3.00819776e-03 1.47034007e-03 6.82151737e-03\n",
      "  4.80672754e-02 4.77483183e-01 4.62702006e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [1.07009964e-06 3.68458946e-04 2.79672179e-08 7.05822385e-05\n",
      "  7.72715151e-01 8.94580409e-03 2.17898935e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [6.71280213e-05 9.75618677e-05 8.41231213e-06 1.51110444e-05\n",
      "  6.54021502e-02 6.52119935e-01 2.82289714e-01]\n",
      " [3.02199860e-05 1.07078682e-04 5.23635299e-06 1.11554391e-05\n",
      "  2.39922032e-02 7.62517601e-02 8.99602413e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [1.31926311e-06 6.93594688e-04 3.27875796e-07 7.28046143e-05\n",
      "  3.24319869e-01 3.12120393e-02 6.43700004e-01]\n",
      " [1.64729499e-04 4.16440598e-04 5.17532999e-06 3.28807946e-05\n",
      "  2.31645003e-01 6.62541509e-01 1.05194204e-01]\n",
      " [4.14094048e-09 9.80286859e-06 2.63578770e-10 5.40418205e-06\n",
      "  7.83989191e-01 1.08176973e-02 2.05177963e-01]\n",
      " [3.02199860e-05 1.07078682e-04 5.23635299e-06 1.11554391e-05\n",
      "  2.39922032e-02 7.62517601e-02 8.99602413e-01]\n",
      " [1.24953394e-05 2.45422943e-05 5.10665268e-06 1.01480655e-05\n",
      "  1.21735977e-02 3.22862625e-01 6.64911449e-01]\n",
      " [4.75268665e-04 7.18713389e-04 6.71418558e-04 2.20448198e-03\n",
      "  5.90642691e-02 6.60159647e-01 2.76706189e-01]\n",
      " [1.02606241e-03 4.03891597e-03 1.43388158e-03 8.43230188e-02\n",
      "  1.30233884e-01 3.24181467e-01 4.54762846e-01]\n",
      " [1.43603678e-03 1.60690909e-03 6.22075284e-04 1.84624374e-03\n",
      "  1.78471401e-01 7.49944806e-01 6.60724863e-02]\n",
      " [4.47477418e-04 3.00819776e-03 1.47034007e-03 6.82151737e-03\n",
      "  4.80672754e-02 4.77483183e-01 4.62702006e-01]\n",
      " [1.36327103e-01 1.86534168e-03 2.53077538e-04 1.19299523e-03\n",
      "  1.76384498e-03 8.55810285e-01 2.78727314e-03]\n",
      " [4.62341189e-01 1.02376211e-02 5.77087572e-04 2.10983492e-03\n",
      "  3.95924877e-03 5.10393858e-01 1.03811836e-02]\n",
      " [2.04390317e-01 1.64592937e-02 1.49241667e-02 3.51162907e-03\n",
      "  1.38959199e-01 5.70767701e-01 5.09876497e-02]\n",
      " [6.89589651e-05 2.68811797e-04 7.21767992e-06 2.70013734e-05\n",
      "  8.99338797e-02 6.06473923e-01 3.03220183e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [3.16285768e-05 3.63749459e-05 5.49743891e-06 1.38476782e-04\n",
      "  3.64101082e-02 2.41978437e-01 7.21399486e-01]\n",
      " [4.90704887e-02 6.87944994e-04 1.64801299e-04 5.32987528e-04\n",
      "  4.11467074e-04 9.33443546e-01 1.56887211e-02]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [5.78350882e-05 7.41472250e-05 6.33885611e-06 2.20707167e-04\n",
      "  8.19721818e-02 2.45712146e-01 6.71956718e-01]\n",
      " [2.34420077e-05 5.13266714e-05 6.04117940e-06 1.65942656e-05\n",
      "  2.81189084e-02 3.36358875e-01 6.35424852e-01]\n",
      " [3.16285768e-05 3.63749459e-05 5.49743891e-06 1.38476782e-04\n",
      "  3.64101082e-02 2.41978437e-01 7.21399486e-01]\n",
      " [8.13968771e-04 1.37216295e-03 7.25105114e-04 3.29081621e-03\n",
      "  1.24545142e-01 6.27850413e-01 2.41402313e-01]\n",
      " [1.52213051e-11 7.99561406e-07 3.13940644e-11 3.38971688e-07\n",
      "  4.94366020e-01 1.23993785e-04 5.05508840e-01]\n",
      " [3.26151758e-01 6.47850288e-03 6.45594788e-04 1.70756457e-03\n",
      "  2.26848782e-03 6.48371696e-01 1.43763935e-02]\n",
      " [6.85277700e-01 2.34531728e-03 1.06809312e-03 2.84814363e-04\n",
      "  2.85447401e-04 3.07211608e-01 3.52704641e-03]\n",
      " [4.65607876e-03 4.43845085e-04 2.86247650e-05 6.88984073e-05\n",
      "  2.90991622e-03 8.99319708e-01 9.25729796e-02]\n",
      " [1.68686420e-01 2.76495479e-02 3.38163227e-02 1.22816870e-02\n",
      "  5.20558894e-01 1.97983220e-01 3.90238725e-02]\n",
      " [2.77845412e-01 1.81809664e-01 5.01165958e-03 4.86174263e-02\n",
      "  4.54015791e-01 1.98693424e-02 1.28308153e-02]\n",
      " [1.66243408e-03 8.26969091e-03 1.67499960e-03 7.02442555e-03\n",
      "  1.78583279e-01 6.66938066e-01 1.35847121e-01]\n",
      " [1.66243408e-03 8.26969091e-03 1.67499960e-03 7.02442555e-03\n",
      "  1.78583279e-01 6.66938066e-01 1.35847121e-01]\n",
      " [3.18157673e-01 9.78810247e-03 7.66543206e-03 1.87589659e-03\n",
      "  1.82908736e-02 6.25883222e-01 1.83386784e-02]\n",
      " [6.13188684e-01 1.39423177e-01 8.97465274e-03 3.70202698e-02\n",
      "  5.14274277e-02 1.08306356e-01 4.16593738e-02]\n",
      " [3.26151758e-01 6.47850288e-03 6.45594788e-04 1.70756457e-03\n",
      "  2.26848782e-03 6.48371696e-01 1.43763935e-02]\n",
      " [4.47477418e-04 3.00819776e-03 1.47034007e-03 6.82151737e-03\n",
      "  4.80672754e-02 4.77483183e-01 4.62702006e-01]\n",
      " [3.26179992e-03 9.31827526e-04 5.47342468e-04 1.33885391e-04\n",
      "  1.21202720e-02 2.69703507e-01 7.13301361e-01]\n",
      " [1.45934173e-05 1.50642614e-03 2.98047098e-07 2.99663865e-04\n",
      "  7.99942076e-01 1.64572913e-02 1.81779608e-01]\n",
      " [9.78494138e-02 3.50452750e-03 5.50509663e-04 2.49515078e-03\n",
      "  1.49717126e-02 8.71970415e-01 8.65834206e-03]\n",
      " [2.27192693e-04 6.26465131e-04 5.39904577e-04 2.11204076e-03\n",
      "  2.99491696e-02 9.33358788e-01 3.31863165e-02]\n",
      " [5.66733149e-07 1.77486494e-04 3.64236961e-08 3.75827622e-05\n",
      "  2.48394370e-01 1.66112166e-02 7.34778821e-01]\n",
      " [8.73671030e-04 7.91445025e-04 1.80713359e-05 5.79808511e-05\n",
      "  1.15412466e-01 8.07079136e-01 7.57672563e-02]\n",
      " [1.28409329e-05 1.50054810e-04 6.95765902e-06 1.14546521e-04\n",
      "  1.23870015e-01 5.78694940e-01 2.97150582e-01]], shape=(91, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(features):\n",
    "    return tf.nn.softmax(tf.matmul(features, W) + b)\n",
    "  \n",
    "print(logistic_regression(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "## $$\n",
    "\\begin{align}\n",
    "loss(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh42tbvItxYP"
   },
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.log(hypothesis) + (1 - labels) * tf.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31628,
     "status": "ok",
     "timestamp": 1561974160049,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "ZOSOjizZtx03",
    "outputId": "110519ac-c33c-4834-f46d-58763f427e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 1.1400\n",
      "Iter: 100, Loss: 0.9999\n",
      "Iter: 200, Loss: 0.8727\n",
      "Iter: 300, Loss: 0.7528\n",
      "Iter: 400, Loss: 0.6395\n",
      "Iter: 500, Loss: 0.5384\n",
      "Iter: 600, Loss: 0.4648\n",
      "Iter: 700, Loss: 0.4232\n",
      "Iter: 800, Loss: 0.3981\n",
      "Iter: 900, Loss: 0.3792\n",
      "Iter: 1000, Loss: 0.3629\n",
      "Iter: 1100, Loss: 0.3482\n",
      "Iter: 1200, Loss: 0.3346\n",
      "Iter: 1300, Loss: 0.3219\n",
      "Iter: 1400, Loss: 0.3099\n",
      "Iter: 1500, Loss: 0.2987\n",
      "Iter: 1600, Loss: 0.2881\n",
      "Iter: 1700, Loss: 0.2780\n",
      "Iter: 1800, Loss: 0.2686\n",
      "Iter: 1900, Loss: 0.2597\n",
      "Iter: 2000, Loss: 0.2512\n",
      "Iter: 2100, Loss: 0.2432\n",
      "Iter: 2200, Loss: 0.2356\n",
      "Iter: 2300, Loss: 0.2285\n",
      "Iter: 2400, Loss: 0.2217\n",
      "Iter: 2500, Loss: 0.2152\n",
      "Iter: 2600, Loss: 0.2091\n",
      "Iter: 2700, Loss: 0.2033\n",
      "Iter: 2800, Loss: 0.1978\n",
      "Iter: 2900, Loss: 0.1926\n",
      "Iter: 3000, Loss: 0.1877\n",
      "Iter: 3100, Loss: 0.1831\n",
      "Iter: 3200, Loss: 0.1787\n",
      "Iter: 3300, Loss: 0.1746\n",
      "Iter: 3400, Loss: 0.1707\n",
      "Iter: 3500, Loss: 0.1670\n",
      "Iter: 3600, Loss: 0.1636\n",
      "Iter: 3700, Loss: 0.1603\n",
      "Iter: 3800, Loss: 0.1572\n",
      "Iter: 3900, Loss: 0.1543\n",
      "Iter: 4000, Loss: 0.1515\n",
      "Iter: 4100, Loss: 0.1488\n",
      "Iter: 4200, Loss: 0.1463\n",
      "Iter: 4300, Loss: 0.1439\n",
      "Iter: 4400, Loss: 0.1416\n",
      "Iter: 4500, Loss: 0.1394\n",
      "Iter: 4600, Loss: 0.1373\n",
      "Iter: 4700, Loss: 0.1353\n",
      "Iter: 4800, Loss: 0.1334\n",
      "Iter: 4900, Loss: 0.1315\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "for step in range(epochs):\n",
    "  for features, labels in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss_value = loss_fn(logistic_regression(features),labels)\n",
    "      grads = tape.gradient(loss_value, [W,b])\n",
    "      optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "      if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),labels)))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vben5FYty5m"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)    \n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31619,
     "status": "ok",
     "timestamp": 1561974160053,
     "user": {
      "displayName": "junseop so",
      "photoUrl": "",
      "userId": "03070847090635331575"
     },
     "user_tz": -540
    },
    "id": "GSS_yRMRt6Pp",
    "outputId": "72abfbfb-877f-446a-e27b-08797850962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 0.9365\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Q2 - Zoo classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
